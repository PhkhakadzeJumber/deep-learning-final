{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70279c9b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:05.341179Z",
     "iopub.status.busy": "2026-01-19T19:45:05.340941Z",
     "iopub.status.idle": "2026-01-19T19:45:16.458975Z",
     "shell.execute_reply": "2026-01-19T19:45:16.458359Z"
    },
    "papermill": {
     "duration": 11.123608,
     "end_time": "2026-01-19T19:45:16.460706",
     "exception": false,
     "start_time": "2026-01-19T19:45:05.337098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. SETUP & IMPORTS\n",
    "# ==========================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "import torchvision.models as models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7a51d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:16.466585Z",
     "iopub.status.busy": "2026-01-19T19:45:16.465913Z",
     "iopub.status.idle": "2026-01-19T19:45:16.531010Z",
     "shell.execute_reply": "2026-01-19T19:45:16.530195Z"
    },
    "papermill": {
     "duration": 0.069468,
     "end_time": "2026-01-19T19:45:16.532542",
     "exception": false,
     "start_time": "2026-01-19T19:45:16.463074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# BEST PRACTICE: Set seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Device configuration (GPU if available, else CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c50146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:16.538159Z",
     "iopub.status.busy": "2026-01-19T19:45:16.537921Z",
     "iopub.status.idle": "2026-01-19T19:45:17.315565Z",
     "shell.execute_reply": "2026-01-19T19:45:17.314685Z"
    },
    "papermill": {
     "duration": 0.786637,
     "end_time": "2026-01-19T19:45:17.321569",
     "exception": false,
     "start_time": "2026-01-19T19:45:16.534932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First (image, caption) pair:\n",
      "('1000268201_693b08cb0e.jpg', 'a child in a pink dress is climbing up a set of stairs in an entry way .')\n",
      "Vocabulary size: 8000\n",
      "Special tokens:\n",
      "{'<pad>': 0, '<unk>': 1, '<s>': 2, '</s>': 3}\n",
      "\n",
      "First caption:\n",
      "a child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "\n",
      "Subword tokens:\n",
      "['▁a', '▁child', '▁in', '▁a', '▁pink', '▁dress', '▁is', '▁climbing', '▁up', '▁a', '▁set', '▁of', '▁stairs', '▁in', '▁an', '▁ent', 'ry', '▁way', '▁.']\n",
      "\n",
      "Subword token IDs:\n",
      "[4, 128, 15, 4, 325, 270, 40, 414, 207, 4, 719, 46, 1045, 15, 135, 1879, 715, 1603, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /kaggle/working/captions_clean.txt\n",
      "  input_format: \n",
      "  model_prefix: /kaggle/working/spm\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: /kaggle/working/captions_clean.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 40455 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=2276235\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9679% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=31\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999679\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 40455 sentences.\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 40455\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 9130\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=88342 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15511 size=20 all=1052 active=1020 piece=▁c\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7958 size=40 all=1637 active=1605 piece=▁r\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5087 size=60 all=2134 active=2102 piece=and\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3960 size=80 all=2658 active=2626 piece=ut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3232 size=100 all=3002 active=2970 piece=ur\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3232 min_freq=83\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2758 size=120 all=3366 active=1301 piece=oo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2447 size=140 all=3814 active=1749 piece=▁ho\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2096 size=160 all=4227 active=2162 piece=▁sk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1786 size=180 all=4448 active=2383 piece=▁standing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1487 size=200 all=4739 active=2674 piece=▁po\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1477 min_freq=93\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1272 size=220 all=4931 active=1170 piece=▁three\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1167 size=240 all=5189 active=1428 piece=▁stre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1034 size=260 all=5378 active=1617 piece=▁mouth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=945 size=280 all=5593 active=1832 piece=▁its\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=831 size=300 all=5752 active=1991 piece=▁mountain\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=830 min_freq=86\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=742 size=320 all=5951 active=1195 piece=▁orange\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=667 size=340 all=6159 active=1403 piece=ak\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=610 size=360 all=6394 active=1638 piece=one\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=575 size=380 all=6572 active=1816 piece=▁bic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=528 size=400 all=6839 active=2083 piece=ps\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=526 min_freq=77\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=487 size=420 all=7062 active=1188 piece=lasses\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=459 size=440 all=7179 active=1305 piece=▁carr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=430 size=460 all=7382 active=1508 piece=nis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=412 size=480 all=7489 active=1615 piece=▁helmet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=385 size=500 all=7618 active=1744 piece=▁race\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=384 min_freq=68\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=359 size=520 all=7727 active=1109 piece=▁base\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=341 size=540 all=7911 active=1293 piece=▁get\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=317 size=560 all=8057 active=1439 piece=are\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=304 size=580 all=8248 active=1630 piece=▁tre\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=288 size=600 all=8405 active=1787 piece=▁players\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=286 min_freq=60\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=266 size=620 all=8500 active=1096 piece=und\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=253 size=640 all=8617 active=1213 piece=▁af\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=245 size=660 all=8789 active=1385 piece=▁am\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=233 size=680 all=8928 active=1524 piece=dd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224 size=700 all=9108 active=1704 piece=▁ice\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=224 min_freq=53\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=211 size=720 all=9175 active=1066 piece=▁collar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=201 size=740 all=9227 active=1118 piece=▁yard\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=193 size=760 all=9262 active=1153 piece=ort\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=182 size=780 all=9379 active=1270 piece=▁todd\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=171 size=800 all=9500 active=1391 piece=ep\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=171 min_freq=49\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=164 size=820 all=9575 active=1061 piece=ican\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=158 size=840 all=9690 active=1176 piece=▁cr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=153 size=860 all=9739 active=1225 piece=▁nearby\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=145 size=880 all=9818 active=1304 piece=▁win\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139 size=900 all=9877 active=1363 piece=▁bott\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=138 min_freq=43\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=133 size=920 all=9952 active=1072 piece=▁house\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=129 size=940 all=10043 active=1163 piece=▁splashing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=125 size=960 all=10110 active=1230 piece=▁obstacle\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=120 size=980 all=10168 active=1288 piece=▁dis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=118 size=1000 all=10211 active=1331 piece=erman\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=118 min_freq=39\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=113 size=1020 all=10277 active=1063 piece=▁male\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=109 size=1040 all=10379 active=1165 piece=▁kis\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104 size=1060 all=10405 active=1191 piece=▁cart\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=100 size=1080 all=10527 active=1313 piece=els\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98 size=1100 all=10583 active=1369 piece=▁vest\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=98 min_freq=35\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=95 size=1120 all=10624 active=1042 piece=ins\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93 size=1140 all=10710 active=1128 piece=▁slo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=90 size=1160 all=10766 active=1184 piece=▁enjo\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87 size=1180 all=10814 active=1232 piece=▁feet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=85 size=1200 all=10917 active=1335 piece=▁cle\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=85 min_freq=32\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83 size=1220 all=10969 active=1045 piece=ike\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=81 size=1240 all=11016 active=1092 piece=▁bare\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=79 size=1260 all=11034 active=1110 piece=▁tank\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=76 size=1280 all=11087 active=1163 piece=ome\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=74 size=1300 all=11150 active=1226 piece=▁ring\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=74 min_freq=28\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73 size=1320 all=11175 active=1024 piece=▁inflatable\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=71 size=1340 all=11264 active=1113 piece=▁mic\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69 size=1360 all=11329 active=1178 piece=pes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=68 size=1380 all=11430 active=1279 piece=▁jackets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=66 size=1400 all=11447 active=1296 piece=mo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=66 min_freq=26\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=65 size=1420 all=11524 active=1053 piece=▁scoot\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63 size=1440 all=11591 active=1120 piece=▁cut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=61 size=1460 all=11620 active=1149 piece=too\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=60 size=1480 all=11661 active=1190 piece=▁scooter\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=58 size=1500 all=11718 active=1247 piece=▁but\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=58 min_freq=24\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57 size=1520 all=11769 active=1047 piece=▁beaut\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=56 size=1540 all=11819 active=1097 piece=eling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55 size=1560 all=11857 active=1135 piece=▁instrum\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=54 size=1580 all=11919 active=1197 piece=▁puppies\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=52 size=1600 all=11965 active=1243 piece=▁way\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=52 min_freq=22\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=1620 all=12019 active=1054 piece=ven\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51 size=1640 all=12065 active=1100 piece=▁gravel\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=1660 all=12122 active=1157 piece=▁dun\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49 size=1680 all=12137 active=1172 piece=▁seated\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48 size=1700 all=12162 active=1197 piece=▁platform\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=48 min_freq=20\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46 size=1720 all=12245 active=1084 piece=▁lit\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45 size=1740 all=12276 active=1115 piece=▁beer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44 size=1760 all=12293 active=1132 piece=read\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=1780 all=12343 active=1182 piece=iding\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43 size=1800 all=12354 active=1193 piece=▁younger\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=43 min_freq=19\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42 size=1820 all=12399 active=1046 piece=▁wrestler\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=41 size=1840 all=12424 active=1071 piece=▁skates\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40 size=1860 all=12457 active=1104 piece=▁falls\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39 size=1880 all=12523 active=1170 piece=▁prof\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38 size=1900 all=12586 active=1233 piece=▁hot\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38 min_freq=17\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=1920 all=12606 active=1019 piece=eds\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37 size=1940 all=12633 active=1046 piece=▁shakes\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=1960 all=12663 active=1076 piece=ering\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36 size=1980 all=12676 active=1089 piece=▁direction\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35 size=2000 all=12717 active=1130 piece=▁straw\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35 min_freq=16\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=2020 all=12755 active=1038 piece=▁leaf\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34 size=2040 all=12759 active=1042 piece=▁kneeling\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33 size=2060 all=12803 active=1086 piece=▁warm\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=2080 all=12843 active=1126 piece=▁cloth\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32 size=2100 all=12835 active=1118 piece=▁construction\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=31 min_freq=15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31 size=2120 all=12867 active=1032 piece=▁fingers\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=2140 all=12909 active=1074 piece=▁rink\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30 size=2160 all=12901 active=1066 piece=▁hillside\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=2180 all=12923 active=1088 piece=▁carri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29 size=2200 all=12914 active=1079 piece=▁photographer\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=29 min_freq=14\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=2220 all=12979 active=1065 piece=▁dune\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28 size=2240 all=12982 active=1068 piece=▁streets\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=2260 all=13016 active=1102 piece=▁spid\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27 size=2280 all=13005 active=1091 piece=▁motorcycles\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=2300 all=13045 active=1131 piece=people\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=26 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26 size=2320 all=13039 active=995 piece=▁crashing\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=2340 all=13074 active=1030 piece=▁bend\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25 size=2360 all=13074 active=1030 piece=▁crosses\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=2380 all=13100 active=1056 piece=ners\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24 size=2400 all=13127 active=1083 piece=▁town\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24 min_freq=13\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=2420 all=13113 active=987 piece=pt\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=2440 all=13188 active=1062 piece=estri\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23 size=2460 all=13197 active=1071 piece=▁sheet\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=2480 all=13203 active=1077 piece=lly\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=2500 all=13255 active=1129 piece=▁exam\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22 min_freq=12\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22 size=2520 all=13257 active=999 piece=▁ribbon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=2540 all=13255 active=997 piece=fa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=2560 all=13327 active=1069 piece=omach\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=2580 all=13327 active=1069 piece=▁leads\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21 size=2600 all=13319 active=1061 piece=▁gymnast\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21 min_freq=11\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=2620 all=13340 active=1021 piece=late\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=2640 all=13378 active=1059 piece=▁sofa\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20 size=2660 all=13383 active=1064 piece=▁church\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=2680 all=13377 active=1058 piece=▁i\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=2700 all=13435 active=1116 piece=ature\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=2720 all=13459 active=1019 piece=▁retur\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19 size=2740 all=13449 active=1009 piece=▁individ\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=2760 all=13466 active=1026 piece=ipe\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=2780 all=13509 active=1069 piece=ifier\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=2800 all=13523 active=1083 piece=▁money\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=10\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18 size=2820 all=13520 active=998 piece=▁picking\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=2840 all=13535 active=1013 piece=nam\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=2860 all=13575 active=1053 piece=▁husk\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=2880 all=13576 active=1054 piece=▁magaz\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=2900 all=13572 active=1050 piece=▁strugg\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17 size=2920 all=13558 active=984 piece=▁partially\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=2940 all=13611 active=1037 piece=▁bad\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=2960 all=13641 active=1067 piece=▁caps\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=2980 all=13646 active=1072 piece=▁sheer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16 size=3000 all=13632 active=1058 piece=▁breaking\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16 min_freq=9\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=3020 all=13650 active=1019 piece=ork\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=3040 all=13693 active=1062 piece=ulars\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=3060 all=13710 active=1079 piece=▁candy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=3080 all=13699 active=1068 piece=▁infant\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=3100 all=13682 active=1051 piece=▁boarding\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15 size=3120 all=13662 active=981 piece=▁approaching\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=3140 all=13723 active=1042 piece=five\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=3160 all=13762 active=1081 piece=white\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=3180 all=13758 active=1077 piece=▁knees\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=3200 all=13747 active=1066 piece=▁similar\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14 min_freq=8\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14 size=3220 all=13732 active=985 piece=▁stretching\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=3240 all=13761 active=1014 piece=▁bor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=3260 all=13791 active=1044 piece=▁lane\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=3280 all=13796 active=1049 piece=▁colour\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=3300 all=13781 active=1034 piece=▁poodles\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13 size=3320 all=13768 active=988 piece=▁stretches\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=3340 all=13789 active=1009 piece=urs\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=3360 all=13812 active=1032 piece=▁dang\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=3380 all=13827 active=1047 piece=▁demon\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=3400 all=13826 active=1046 piece=▁babies\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=3420 all=13817 active=992 piece=▁vendor\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12 size=3440 all=13802 active=977 piece=▁railings\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3460 all=13816 active=991 piece=bag\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3480 all=13867 active=1042 piece=▁tar\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3500 all=13891 active=1066 piece=▁wade\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11 min_freq=7\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3520 all=13901 active=1011 piece=▁scrat\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3540 all=13893 active=1003 piece=▁tights\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3560 all=13883 active=993 piece=▁demonstr\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11 size=3580 all=13871 active=981 piece=▁waterskier\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3600 all=13902 active=1012 piece=cord\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3620 all=13947 active=1044 piece=▁zip\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3640 all=13965 active=1062 piece=▁bent\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3660 all=13962 active=1059 piece=▁seas\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3680 all=13962 active=1059 piece=▁pours\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3700 all=13955 active=1052 piece=▁firing\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3720 all=13940 active=986 piece=▁carried\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3740 all=13921 active=967 piece=▁lacrosse\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10 size=3760 all=13906 active=952 piece=▁transport\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3780 all=13926 active=972 piece=ram\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3800 all=13962 active=1008 piece=made\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3820 all=14001 active=1038 piece=aters\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3840 all=14030 active=1067 piece=▁chop\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3860 all=14043 active=1080 piece=sticks\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3880 all=14041 active=1078 piece=▁movie\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3900 all=14032 active=1069 piece=▁aiming\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=6\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3920 all=14017 active=986 piece=▁sister\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3940 all=14002 active=971 piece=▁parents\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3960 all=13988 active=957 piece=▁extended\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=3980 all=13968 active=937 piece=▁badminton\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9 size=4000 all=13950 active=919 piece=▁mountainous\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4020 all=13999 active=1050 piece=▁sy\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4040 all=14040 active=1091 piece=umer\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4060 all=14079 active=1130 piece=▁use\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4080 all=14098 active=1149 piece=▁keep\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4100 all=14111 active=1162 piece=barrow\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8 min_freq=5\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4120 all=14099 active=988 piece=▁press\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4140 all=14099 active=988 piece=▁clings\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8 size=4160 all=14085 active=974 piece=▁baseman\n",
      "bpe_model_trainer.cc("
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "file_path = '/kaggle/input/flickr8k/captions.txt'\n",
    "\n",
    "# read file\n",
    "img_caption_pairs = []\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Remove header\n",
    "lines = lines[1:]\n",
    "\n",
    "for line in lines:\n",
    "    img, caption = line.split(',', 1)\n",
    "    img_caption_pairs.append((img, caption.lower()))\n",
    "\n",
    "print(\"First (image, caption) pair:\")\n",
    "print(img_caption_pairs[0])\n",
    "\n",
    "# save only captions for tokenizer\n",
    "captions_file = '/kaggle/working/captions_clean.txt'\n",
    "\n",
    "with open(captions_file, 'w', encoding='utf-8') as f:\n",
    "    for _, caption in img_caption_pairs:\n",
    "        f.write(caption + '\\n')\n",
    "\n",
    "# train tokenizer\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=captions_file,\n",
    "    model_prefix='/kaggle/working/spm',\n",
    "    vocab_size=8000,\n",
    "    model_type='bpe',\n",
    "    pad_id=0,\n",
    "    unk_id=1,\n",
    "    bos_id=2,\n",
    "    eos_id=3\n",
    ")\n",
    "\n",
    "# load tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('/kaggle/working/spm.model')\n",
    "\n",
    "# building vocabulary\n",
    "vocab = {sp.id_to_piece(i): i for i in range(sp.get_piece_size())}\n",
    "\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"Special tokens:\")\n",
    "print({k: v for k, v in vocab.items() if k in [\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"]})\n",
    "\n",
    "# Example: subword tokenization of first caption\n",
    "first_caption = img_caption_pairs[0][1]\n",
    "\n",
    "subword_tokens = sp.encode(first_caption, out_type=str)\n",
    "subword_ids = sp.encode(first_caption, out_type=int)\n",
    "\n",
    "print(\"\\nFirst caption:\")\n",
    "print(first_caption)\n",
    "\n",
    "print(\"\\nSubword tokens:\")\n",
    "print(subword_tokens)\n",
    "\n",
    "print(\"\\nSubword token IDs:\")\n",
    "print(subword_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95db963d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:17.334019Z",
     "iopub.status.busy": "2026-01-19T19:45:17.333558Z",
     "iopub.status.idle": "2026-01-19T19:45:17.341730Z",
     "shell.execute_reply": "2026-01-19T19:45:17.340919Z"
    },
    "papermill": {
     "duration": 0.016096,
     "end_time": "2026-01-19T19:45:17.343830",
     "exception": false,
     "start_time": "2026-01-19T19:45:17.327734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class ImageCaptionDataset(Dataset):\n",
    "    def __init__(self, img_caption_pairs, sp, image_root, transform=None):\n",
    "        self.data = img_caption_pairs\n",
    "        self.sp = sp # tokenizer\n",
    "        self.image_root = image_root # path where the images are\n",
    "        self.transform = transform\n",
    "\n",
    "        self.bos_id = sp.bos_id()\n",
    "        self.eos_id = sp.eos_id()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, caption = self.data[idx]\n",
    "\n",
    "        # ---- Load image ----\n",
    "        img_path = f\"{self.image_root}/{img_name}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # ---- Tokenize caption ----\n",
    "        caption_ids = self.sp.encode(caption, out_type=int)\n",
    "\n",
    "        # Add <bos> and <eos>\n",
    "        caption_ids = [self.bos_id] + caption_ids + [self.eos_id]\n",
    "\n",
    "        caption_tensor = torch.tensor(caption_ids, dtype=torch.long)\n",
    "\n",
    "        return image, caption_tensor, len(caption_tensor)\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4ad149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:17.352642Z",
     "iopub.status.busy": "2026-01-19T19:45:17.352230Z",
     "iopub.status.idle": "2026-01-19T19:45:17.356814Z",
     "shell.execute_reply": "2026-01-19T19:45:17.356073Z"
    },
    "papermill": {
     "duration": 0.011489,
     "end_time": "2026-01-19T19:45:17.358955",
     "exception": false,
     "start_time": "2026-01-19T19:45:17.347466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, captions, lengths = zip(*batch)\n",
    "\n",
    "    images = torch.stack(images, dim=0)\n",
    "\n",
    "    captions_padded = pad_sequence(\n",
    "        captions,\n",
    "        batch_first=True,\n",
    "        padding_value=sp.pad_id()\n",
    "    )\n",
    "\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    return images, captions_padded, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dd08ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:17.368411Z",
     "iopub.status.busy": "2026-01-19T19:45:17.368111Z",
     "iopub.status.idle": "2026-01-19T19:45:17.401060Z",
     "shell.execute_reply": "2026-01-19T19:45:17.400304Z"
    },
    "papermill": {
     "duration": 0.039189,
     "end_time": "2026-01-19T19:45:17.402615",
     "exception": false,
     "start_time": "2026-01-19T19:45:17.363426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train/val split\n",
    "\n",
    "img_to_captions = defaultdict(list)\n",
    "\n",
    "for img, caption in img_caption_pairs:\n",
    "  img_to_captions[img].append(caption)\n",
    "\n",
    "all_images = list(img_to_captions.keys())\n",
    "\n",
    "train_images, val_images = train_test_split(\n",
    "    all_images,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "train_pairs = []\n",
    "val_pairs = []\n",
    "\n",
    "for img in train_images:\n",
    "  for caption in img_to_captions[img]:\n",
    "    train_pairs.append((img, caption))\n",
    "\n",
    "for img in val_images:\n",
    "  for caption in img_to_captions[img]:\n",
    "    val_pairs.append((img, caption))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6497a1ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:17.409238Z",
     "iopub.status.busy": "2026-01-19T19:45:17.408668Z",
     "iopub.status.idle": "2026-01-19T19:45:19.093276Z",
     "shell.execute_reply": "2026-01-19T19:45:19.091978Z"
    },
    "papermill": {
     "duration": 1.692939,
     "end_time": "2026-01-19T19:45:19.098269",
     "exception": false,
     "start_time": "2026-01-19T19:45:17.405330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: torch.Size([64, 3, 256, 256])\n",
      "Captions: torch.Size([64, 24])\n",
      "Lengths: tensor([17,  9, 13, 10, 17, 17, 14,  9, 12, 16,  9, 12, 12, 12, 20, 16, 11, 20,\n",
      "        16, 22, 11, 10, 19, 21, 12, 11, 20, 17, 14, 10, 12, 15, 24, 10, 12, 14,\n",
      "        16, 17,  7, 21, 19, 10, 12, 14, 15, 14, 11, 20, 12,  9, 15,  9, 15, 15,\n",
      "        19,  9, 13, 12, 21, 18, 18, 13, 14, 12])\n"
     ]
    }
   ],
   "source": [
    "image_root = '/kaggle/input/flickr8k/Images'\n",
    "\n",
    "train_dataset = ImageCaptionDataset(train_pairs, sp, image_root, transform=image_transform)\n",
    "val_dataset   = ImageCaptionDataset(val_pairs, sp, image_root, transform=image_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=4,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=True   # keeps workers alive between epochs\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "images, captions, lengths = next(iter(train_loader))\n",
    "\n",
    "print(\"Images:\", images.shape)        # (B, 3, 256, 256)\n",
    "print(\"Captions:\", captions.shape)    # (B, max_len)\n",
    "print(\"Lengths:\", lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c54da67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:19.111980Z",
     "iopub.status.busy": "2026-01-19T19:45:19.111158Z",
     "iopub.status.idle": "2026-01-19T19:45:21.639576Z",
     "shell.execute_reply": "2026-01-19T19:45:21.638548Z"
    },
    "papermill": {
     "duration": 2.53751,
     "end_time": "2026-01-19T19:45:21.642560",
     "exception": false,
     "start_time": "2026-01-19T19:45:19.105050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 75.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 42,247,040\n"
     ]
    }
   ],
   "source": [
    "class ImgToCaptionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=512, max_seq_len=50, pad_token_id=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.pad_token_id = pad_token_id\n",
    "        \n",
    "        # CNN ENCODER (pretrained ResNet-50)\n",
    "        # input:  256 x 256 x 3\n",
    "        # conv1:  128 x 128 x 64      (64 filters 7x7x3, stride = 2)\n",
    "        # pool:    64 x 64 x 64       (3x3 maxpool, stride = 2, padding = 1)\n",
    "        # layer1:  64 x 64 x 256      (Bottleneck: (64) 1×1 → (64) 3×3 (stride=1) → (256) 1×1)\n",
    "        # layer2:  32 x 32 x 512      (Bottleneck, stride = 2)\n",
    "        # layer3:  16 x 16 x 1024     (Bottleneck, stride = 2)\n",
    "        # layer4:   8 x 8 x 2048      (Bottleneck, stride = 2)\n",
    "\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(resnet.children())[:-2])  # (B, 2048, 8, 8)\n",
    "\n",
    "        # Project visual features\n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Linear(2048, embed_dim),\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "        # TEXT EMBEDDING\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.embed_dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.pos_encoding = nn.Parameter(\n",
    "            torch.randn(max_seq_len, embed_dim) * 0.02\n",
    "        )\n",
    "\n",
    "        # TRANSFORMER DECODER\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=8,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=3\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        # IMAGE ENCODING\n",
    "        img_features = self.cnn(images)               # (B, 2048, 8, 8)\n",
    "        img_features = img_features.flatten(2)        # (B, 2048, 64)\n",
    "        img_features = img_features.transpose(1, 2)   # (B, 64, 2048)\n",
    "        img_features = self.prep(img_features)        # (B, 64, 512)\n",
    "        \n",
    "        # TEXT EMBEDDING\n",
    "        seq_len = captions.size(1)\n",
    "        caption_embeds = self.embedding(captions)\n",
    "        caption_embeds = self.embed_dropout(caption_embeds)\n",
    "        caption_embeds = caption_embeds + self.pos_encoding[:seq_len]\n",
    "\n",
    "        # MASKS\n",
    "        tgt_mask = torch.triu(\n",
    "            torch.ones(seq_len, seq_len, device=captions.device, dtype=torch.bool),\n",
    "            diagonal=1\n",
    "        )\n",
    "\n",
    "        tgt_key_padding_mask = (captions == self.pad_token_id)\n",
    "\n",
    "        # DECODER\n",
    "        output = self.transformer_decoder(\n",
    "            tgt=caption_embeds,\n",
    "            memory=img_features,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask\n",
    "        )\n",
    "\n",
    "        output = self.fc_out(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Initialize the model\n",
    "vocab_size = 8000\n",
    "model = ImgToCaptionModel(vocab_size=vocab_size, embed_dim=512, max_seq_len=50, pad_token_id=0)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Parameters: {total_params:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c928e79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:21.655857Z",
     "iopub.status.busy": "2026-01-19T19:45:21.655475Z",
     "iopub.status.idle": "2026-01-19T19:45:21.665989Z",
     "shell.execute_reply": "2026-01-19T19:45:21.665232Z"
    },
    "papermill": {
     "duration": 0.018912,
     "end_time": "2026-01-19T19:45:21.667500",
     "exception": false,
     "start_time": "2026-01-19T19:45:21.648588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# perplexity metric calculation (better indicator than just raw loss function)\n",
    "\n",
    "def perplexity_from_loss(loss):\n",
    "    return math.exp(loss) if loss < 20 else float(\"inf\")\n",
    "    \n",
    "# BLEU-1 (single word overlap) metric calculation (mostly used indicator)\n",
    "\n",
    "def bleu1_score(pred_tokens, ref_tokens):\n",
    "    pred_counts = Counter(pred_tokens)\n",
    "    ref_counts = Counter(ref_tokens)\n",
    "    overlap = sum(min(pred_counts[w], ref_counts[w]) for w in pred_counts)\n",
    "    return overlap / max(1, len(pred_tokens))\n",
    "\n",
    "def greedy_decode(model, image, max_len, start_token_id, end_token_id):\n",
    "    model.eval()\n",
    "    caption = torch.tensor([[start_token_id]], device=image.device)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        outputs = model(image, caption)\n",
    "        next_token = outputs[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "        caption = torch.cat([caption, next_token], dim=1)\n",
    "\n",
    "        if next_token.item() == end_token_id:\n",
    "            break\n",
    "\n",
    "    return caption.squeeze(0).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42f46d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T19:45:21.679179Z",
     "iopub.status.busy": "2026-01-19T19:45:21.678956Z",
     "iopub.status.idle": "2026-01-19T20:50:23.265581Z",
     "shell.execute_reply": "2026-01-19T20:50:23.264561Z"
    },
    "papermill": {
     "duration": 3901.600064,
     "end_time": "2026-01-19T20:50:23.271445",
     "exception": false,
     "start_time": "2026-01-19T19:45:21.671381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [1/15]\n",
      "   Train Loss: 4.4325\n",
      "   Train PPL:  84.15\n",
      "   Val Loss:   3.8031\n",
      "   Val PPL:    44.84\n",
      "   Val BLEU-1 (approx): 0.3977\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [2/15]\n",
      "   Train Loss: 3.5952\n",
      "   Train PPL:  36.42\n",
      "   Val Loss:   3.5472\n",
      "   Val PPL:    34.72\n",
      "   Val BLEU-1 (approx): 0.3753\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [3/15]\n",
      "   Train Loss: 3.3060\n",
      "   Train PPL:  27.28\n",
      "   Val Loss:   3.4299\n",
      "   Val PPL:    30.87\n",
      "   Val BLEU-1 (approx): 0.3809\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [4/15]\n",
      "   Train Loss: 3.1050\n",
      "   Train PPL:  22.31\n",
      "   Val Loss:   3.3708\n",
      "   Val PPL:    29.10\n",
      "   Val BLEU-1 (approx): 0.3862\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [5/15]\n",
      "   Train Loss: 2.9498\n",
      "   Train PPL:  19.10\n",
      "   Val Loss:   3.3375\n",
      "   Val PPL:    28.15\n",
      "   Val BLEU-1 (approx): 0.4185\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [6/15]\n",
      "   Train Loss: 2.8203\n",
      "   Train PPL:  16.78\n",
      "   Val Loss:   3.3247\n",
      "   Val PPL:    27.79\n",
      "   Val BLEU-1 (approx): 0.4159\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Epoch [7/15]\n",
      "   Train Loss: 2.7064\n",
      "   Train PPL:  14.98\n",
      "   Val Loss:   3.3201\n",
      "   Val PPL:    27.66\n",
      "   Val BLEU-1 (approx): 0.3899\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "\n",
      "📊 Epoch [8/15]\n",
      "   Train Loss: 2.6053\n",
      "   Train PPL:  13.54\n",
      "   Val Loss:   3.3207\n",
      "   Val PPL:    27.68\n",
      "   Val BLEU-1 (approx): 0.3947\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "\n",
      "📊 Epoch [9/15]\n",
      "   Train Loss: 2.5089\n",
      "   Train PPL:  12.29\n",
      "   Val Loss:   3.3264\n",
      "   Val PPL:    27.84\n",
      "   Val BLEU-1 (approx): 0.3879\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "\n",
      "📊 Epoch [10/15]\n",
      "   Train Loss: 2.4216\n",
      "   Train PPL:  11.26\n",
      "   Val Loss:   3.3398\n",
      "   Val PPL:    28.21\n",
      "   Val BLEU-1 (approx): 0.3984\n",
      "   LR (CNN):      0.000010\n",
      "   LR (Transformer): 0.000100\n",
      "\n",
      "📊 Epoch [11/15]\n",
      "   Train Loss: 2.3396\n",
      "   Train PPL:  10.38\n",
      "   Val Loss:   3.3577\n",
      "   Val PPL:    28.72\n",
      "   Val BLEU-1 (approx): 0.3972\n",
      "   LR (CNN):      0.000005\n",
      "   LR (Transformer): 0.000050\n",
      "\n",
      "📊 Epoch [12/15]\n",
      "   Train Loss: 2.2122\n",
      "   Train PPL:  9.14\n",
      "   Val Loss:   3.3734\n",
      "   Val PPL:    29.18\n",
      "   Val BLEU-1 (approx): 0.3872\n",
      "   LR (CNN):      0.000005\n",
      "   LR (Transformer): 0.000050\n",
      "\n",
      "📊 Epoch [13/15]\n",
      "   Train Loss: 2.1622\n",
      "   Train PPL:  8.69\n",
      "   Val Loss:   3.3868\n",
      "   Val PPL:    29.57\n",
      "   Val BLEU-1 (approx): 0.3911\n",
      "   LR (CNN):      0.000005\n",
      "   LR (Transformer): 0.000050\n",
      "\n",
      "📊 Epoch [14/15]\n",
      "   Train Loss: 2.1172\n",
      "   Train PPL:  8.31\n",
      "   Val Loss:   3.4119\n",
      "   Val PPL:    30.32\n",
      "   Val BLEU-1 (approx): 0.3858\n",
      "   LR (CNN):      0.000005\n",
      "   LR (Transformer): 0.000050\n",
      "\n",
      "📊 Epoch [15/15]\n",
      "   Train Loss: 2.0765\n",
      "   Train PPL:  7.98\n",
      "   Val Loss:   3.4345\n",
      "   Val PPL:    31.02\n",
      "   Val BLEU-1 (approx): 0.3763\n",
      "   LR (CNN):      0.000003\n",
      "   LR (Transformer): 0.000025\n",
      "\n",
      "✅ Training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15                   \n",
    "learning_rate = 1e-4  \n",
    "\n",
    "pad_token_id = 0\n",
    "start_token_id = 2  \n",
    "end_token_id = 3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_token_id, label_smoothing=0.05)\n",
    "\n",
    "# Separate CNN and other parameters for different learning rates\n",
    "cnn_params = list(model.cnn.parameters())\n",
    "other_params = [p for n, p in model.named_parameters() if not n.startswith(\"cnn\")]\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': cnn_params, 'lr': 1e-5},        # slow LR for pretrained CNN\n",
    "    {'params': other_params, 'lr': 1e-4}       # higher LR for transformer & prep layers\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler \n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# For saving best model\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # ========== TRAIN ==========\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, captions, lengths in train_loader:\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "\n",
    "        inputs = captions[:, :-1]\n",
    "        targets = captions[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = model(images, inputs)\n",
    "            loss = criterion(\n",
    "                outputs.reshape(-1, outputs.size(-1)),\n",
    "                targets.reshape(-1)\n",
    "            )\n",
    "\n",
    "        # Backprop with AMP\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Unscale before clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_ppl = perplexity_from_loss(avg_train_loss)\n",
    "\n",
    "    # ========== VALIDATION ==========\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    bleu_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, captions, lengths in val_loader:\n",
    "            images = images.to(device)\n",
    "            captions = captions.to(device)\n",
    "\n",
    "            inputs = captions[:, :-1]\n",
    "            targets = captions[:, 1:]\n",
    "\n",
    "            with autocast(device_type='cuda'):\n",
    "                outputs = model(images, inputs)\n",
    "                loss = criterion(\n",
    "                    outputs.reshape(-1, outputs.size(-1)),\n",
    "                    targets.reshape(-1)\n",
    "                )\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # BLEU-1 (1 image per batch)\n",
    "            image = images[0].unsqueeze(0)\n",
    "            reference = captions[0].tolist()\n",
    "            reference = [\n",
    "                t for t in reference\n",
    "                if t not in {pad_token_id, start_token_id, end_token_id}\n",
    "            ]\n",
    "\n",
    "            prediction = greedy_decode(\n",
    "                model,\n",
    "                image,\n",
    "                max_len=50,\n",
    "                start_token_id=start_token_id,\n",
    "                end_token_id=end_token_id\n",
    "            )\n",
    "\n",
    "            prediction = [\n",
    "                t for t in prediction\n",
    "                if t not in {pad_token_id, start_token_id, end_token_id}\n",
    "            ]\n",
    "            \n",
    "            bleu_scores.append(bleu1_score(prediction, reference))\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_ppl = perplexity_from_loss(avg_val_loss)\n",
    "    avg_bleu1 = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), '/kaggle/working/image_caption_model.pth')\n",
    "        print(\"✅ Best model saved!\")\n",
    "\n",
    "    print(f\"\\n📊 Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   Train PPL:  {train_ppl:.2f}\")\n",
    "    print(f\"   Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"   Val PPL:    {val_ppl:.2f}\")\n",
    "    print(f\"   Val BLEU-1 (approx): {avg_bleu1:.4f}\")\n",
    "    print(f\"   LR (CNN):      {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(f\"   LR (Transformer): {optimizer.param_groups[1]['lr']:.6f}\")\n",
    "\n",
    "print(\"\\n✅ Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 623289,
     "sourceId": 1111676,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3923.333087,
   "end_time": "2026-01-19T20:50:26.095125",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-19T19:45:02.762038",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
