{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"6w5STuNd1sfp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767172989833,"user_tz":-240,"elapsed":24907,"user":{"displayName":"Juba Pxakadze","userId":"03422873617070995945"}},"outputId":"56277579-b0b9-4db6-b9ce-68e5926c4801"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Go to notebook folder\n","#cd /content/drive/MyDrive/Colab\\ Notebooks/\n"]},{"cell_type":"code","source":["# ==========================================\n","# 1. SETUP & IMPORTS\n","# ==========================================\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import re\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report"],"metadata":{"id":"duajBSSlU62X","executionInfo":{"status":"ok","timestamp":1767172997688,"user_tz":-240,"elapsed":5303,"user":{"displayName":"Juba Pxakadze","userId":"03422873617070995945"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# BEST PRACTICE: Set seeds for reproducibility\n","SEED = 42\n","torch.manual_seed(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","# Device configuration (GPU if available, else CPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajoSWjYUVHzR","executionInfo":{"status":"ok","timestamp":1767173001355,"user_tz":-240,"elapsed":100,"user":{"displayName":"Juba Pxakadze","userId":"03422873617070995945"}},"outputId":"7871f510-83a3-4364-b222-be66b0a5fe95"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["import sentencepiece as spm\n","\n","file_path = '/content/drive/MyDrive/caption_data/captions.txt'\n","\n","# read file\n","img_caption_pairs = []\n","\n","with open(file_path, 'r', encoding='utf-8') as f:\n","    lines = [line.strip() for line in f if line.strip()]\n","\n","# Remove header\n","lines = lines[1:]\n","\n","for line in lines:\n","    img, caption = line.split(',', 1)\n","    img_caption_pairs.append((img, caption.lower()))\n","\n","print(\"First (image, caption) pair:\")\n","print(img_caption_pairs[0])\n","\n","# save only captions for tokenizer\n","captions_file = '/content/captions_clean.txt'\n","\n","with open(captions_file, 'w', encoding='utf-8') as f:\n","    for _, caption in img_caption_pairs:\n","        f.write(caption + '\\n')\n","\n","# train tokenizer\n","spm.SentencePieceTrainer.train(\n","    input=captions_file,\n","    model_prefix='/content/spm',\n","    vocab_size=8000,\n","    model_type='bpe',\n","    pad_id=0,\n","    unk_id=1,\n","    bos_id=2,\n","    eos_id=3\n",")\n","\n","# load tokenizer\n","sp = spm.SentencePieceProcessor()\n","sp.load('/content/spm.model')\n","\n","# building vocabulary\n","vocab = {sp.id_to_piece(i): i for i in range(sp.get_piece_size())}\n","\n","print(\"Vocabulary size:\", len(vocab))\n","print(\"Special tokens:\")\n","print({k: v for k, v in vocab.items() if k in [\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"]})\n","\n","# Example: subword tokenization of first caption\n","first_caption = img_caption_pairs[0][1]\n","\n","subword_tokens = sp.encode(first_caption, out_type=str)\n","subword_ids = sp.encode(first_caption, out_type=int)\n","\n","print(\"\\nFirst caption:\")\n","print(first_caption)\n","\n","print(\"\\nSubword tokens:\")\n","print(subword_tokens)\n","\n","print(\"\\nSubword token IDs:\")\n","print(subword_ids)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJ7s2RjTVTLN","executionInfo":{"status":"ok","timestamp":1767174842007,"user_tz":-240,"elapsed":833,"user":{"displayName":"Juba Pxakadze","userId":"03422873617070995945"}},"outputId":"8082c90c-1613-4189-f3ef-23755cbb0f23"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["First (image, caption) pair:\n","('1000268201_693b08cb0e.jpg', 'a child in a pink dress is climbing up a set of stairs in an entry way .')\n","Vocabulary size: 8000\n","Special tokens:\n","{'<pad>': 0, '<unk>': 1, '<s>': 2, '</s>': 3}\n","\n","First caption:\n","a child in a pink dress is climbing up a set of stairs in an entry way .\n","\n","Subword tokens:\n","['▁a', '▁child', '▁in', '▁a', '▁pink', '▁dress', '▁is', '▁climbing', '▁up', '▁a', '▁set', '▁of', '▁stairs', '▁in', '▁an', '▁ent', 'ry', '▁way', '▁.']\n","\n","Subword token IDs:\n","[4, 128, 15, 4, 325, 270, 40, 414, 207, 4, 719, 46, 1045, 15, 135, 1879, 715, 1603, 7]\n"]}]}]}